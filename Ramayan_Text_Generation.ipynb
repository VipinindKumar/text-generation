{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ramayan Text Generation.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tkA6Nv00jzeq",
        "colab_type": "text"
      },
      "source": [
        "# Text generation using textgenrnn:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gG8uSt3ZkHOA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -q textgenrnn\n",
        "from google.colab import files\n",
        "from textgenrnn import textgenrnn\n",
        "from datetime import datetime\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vcppfaj_QlQz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_cfg = {\n",
        "    'word_level': False,   # set to True if want to train a word-level model (requires more data and smaller max_length)\n",
        "    'rnn_size': 128,   # number of LSTM cells of each layer (128/256 recommended)\n",
        "    'rnn_layers': 3,   # number of LSTM layers (>=2 recommended)\n",
        "    'rnn_bidirectional': False,   # consider text both forwards and backward, can give a training boost\n",
        "    'max_length': 30,   # number of tokens to consider before predicting the next (20-40 for characters, 5-10 for words recommended)\n",
        "    'max_words': 10000,   # maximum number of words to model; the rest will be ignored (word-level model only)\n",
        "}\n",
        "\n",
        "train_cfg = {\n",
        "    'line_delimited': False,   # set to True if each text has its own line in the source file\n",
        "    'num_epochs': 20,   # set higher to train the model for longer\n",
        "    'gen_epochs': 5,   # generates sample text from model after given number of epochs\n",
        "    'train_size': 0.8,   # proportion of input data to train on: setting < 1.0 limits model from learning perfectly\n",
        "    'dropout': 0.0,   # ignore a random proportion of source tokens each epoch, allowing model to generalize better\n",
        "    'validation': False,   # If train__size < 1.0, test on holdout dataset; will make overall training slower\n",
        "    'is_csv': False   # set to True if file is a CSV exported from Excel/BigQuery/pandas\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQxw6j9WQvH3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6c29940a-fd1c-46b0-db28-a538f6fe1d0e"
      },
      "source": [
        "textgen = textgenrnn(name='ramayan RNN')\n",
        "\n",
        "train_function = textgen.train_from_file if train_cfg['line_delimited'] else textgen.train_from_largetext_file\n",
        "\n",
        "train_function(\n",
        "    file_path='ram.txt',\n",
        "    new_model=True,\n",
        "    num_epochs=train_cfg['num_epochs'],\n",
        "    gen_epochs=train_cfg['gen_epochs'],\n",
        "    batch_size=1024,\n",
        "    train_size=train_cfg['train_size'],\n",
        "    dropout=train_cfg['dropout'],\n",
        "    validation=train_cfg['validation'],\n",
        "    is_csv=train_cfg['is_csv'],\n",
        "    rnn_layers=model_cfg['rnn_layers'],\n",
        "    rnn_size=model_cfg['rnn_size'],\n",
        "    rnn_bidirectional=model_cfg['rnn_bidirectional'],\n",
        "    max_length=model_cfg['max_length'],\n",
        "    dim_embeddings=100,\n",
        "    word_level=model_cfg['word_level'])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training new model w/ 3-layer, 128-cell LSTMs\n",
            "Training on 2,592,926 character sequences.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Epoch 1/20\n",
            "2532/2532 [==============================] - 336s 133ms/step - loss: 2.0040\n",
            "Epoch 2/20\n",
            "2532/2532 [==============================] - 333s 132ms/step - loss: 1.2608\n",
            "Epoch 3/20\n",
            "2532/2532 [==============================] - 332s 131ms/step - loss: 1.1801\n",
            "Epoch 4/20\n",
            "2532/2532 [==============================] - 333s 132ms/step - loss: 1.1399\n",
            "Epoch 5/20\n",
            "2532/2532 [==============================] - 331s 131ms/step - loss: 1.1127\n",
            "####################\n",
            "Temperature: 0.2\n",
            "####################\n",
            "on of the \n",
            "sages, the titans and the powerful \n",
            "Ravana and the son of Dasaratha, who was able to disport the son of \n",
            "Dasaratha and the son of Dasaratha and the \n",
            "monkeys and the son of Dasaratha and \n",
            "the foremost of the Rakshasas and \n",
            "the son of Ravana's heart and the \n",
            "sun and the son of the Wind-god \n",
            "\n",
            " of Dasaratha and \n",
            "the son of Vayu, the son of Dasaratha, \n",
            "who was subject to the sun and \n",
            "the son of Dasaratha and Shri Ramachandra and \n",
            "the son of the Gods, the King of the Monkeys, \n",
            "who was able to change the sun and \n",
            "the sun in the presence of the \n",
            "forest and the head of the powerful \n",
            "Ravana and\n",
            "\n",
            " and the son of Dasaratha and the \n",
            "sun and the son of Dasaratha and \n",
            "the son of Vasava, the King of the Monkeys, having set out from the sun and \n",
            "arrows and the son of the Wind-god \n",
            "and the titans with the army of the \n",
            "sun and the son of Dasaratha, the \n",
            "son of Dasaratha and having slain the \n",
            "monkeys\n",
            "\n",
            "####################\n",
            "Temperature: 0.5\n",
            "####################\n",
            " the whole \n",
            "enemy region and first and the son of \n",
            "Dasaratha nor the resplendent \n",
            "Karusha and Mahadeva and his desires \n",
            "and a desert and for the lonely \n",
            "formerly and the titans with his prowess \n",
            "and the foremost of the Rakshasas and the \n",
            "holy sage, showing to the dark- \n",
            "abode of the titans? It is th\n",
            "\n",
            "keys with the \n",
            "approprate army of the forest, the foremost of the Rakshasas, \n",
            "the king in a vast army of the Shri \n",
            "Vishnu, the sound of the King of the Titans, the princesses of the fruit of the conclusion of the Gandharvas and those who are ever the \n",
            "foremost of the Rakshasas, who \n",
            "had the struggle\n",
            "\n",
            "ain and the river of the death of the \n",
            "sages, and, having spoken thus :- \n",
            "cc Whose anger as the sun and \n",
            "said:- \n",
            "\" 0 Illustrious One, and the whole \n",
            "world was not able to sping of the \n",
            "sun, that sage will fast on their capital \n",
            "consort of the three monkeys with the arrival, the son of Vayu, \n",
            "and off\n",
            "\n",
            "####################\n",
            "Temperature: 1.0\n",
            "####################\n",
            "d which, eager happily in his sire, \n",
            "having fell into that mountain has been virtuous! The virtuous \n",
            "cave. On this, the army of those peacocks full; my foe's \n",
            "wonder, I shall not behold her subject! \n",
            "Belong; I wish to instruct thee. 0 Sita, \n",
            "the great Guhour and their lips crush. Having been overcom\n",
            "\n",
            " titan. 0 Shymi- \n",
            "un-A magnanimous Kinneras, and enchanting the ware of large residence, \n",
            "paying home for Ravana's foes, perling from the \n",
            "powerful Gient of a maning are harased \n",
            "hence I resembles long times! U Rama esteemons. \n",
            "There-did the musical and army, \n",
            "imitant like the chyst shafts. \n",
            "Deferen\n",
            "\n",
            "having effering his grief, we struck \n",
            "the General King Vishalya :- \n",
            "\" \n",
            "Having thus alarmed and all the monarch Happora, the enchanting \n",
            "powerful treshing illustrious forevers in oder slaying the extent him, Sugriva payed to Shri Vritrara! At \n",
            "that herbit, to these words that the illustrious Rama mov\n",
            "\n",
            "Epoch 6/20\n",
            "2532/2532 [==============================] - 328s 129ms/step - loss: 1.0920\n",
            "Epoch 7/20\n",
            "2532/2532 [==============================] - 337s 133ms/step - loss: 1.0743\n",
            "Epoch 8/20\n",
            "2532/2532 [==============================] - 338s 133ms/step - loss: 1.0590\n",
            "Epoch 9/20\n",
            "2532/2532 [==============================] - 336s 133ms/step - loss: 1.0450\n",
            "Epoch 10/20\n",
            "2532/2532 [==============================] - 334s 132ms/step - loss: 1.0320\n",
            "####################\n",
            "Temperature: 0.2\n",
            "####################\n",
            "ns of King Dasaratha, \n",
            "the monkeys for the same fire in the \n",
            "forest, the monkeys resembled a cloud \n",
            "of pearls and the consort of Rama, \n",
            "the foremost of the monkeys and the \n",
            "monkeys and the titans with the \n",
            "hermitage and the son of Dasaratha, \n",
            "the monkeys and the sages and the \n",
            "monkeys and the sacred\n",
            "\n",
            "s of the monkeys and \n",
            "the sages and all the sages and \n",
            "the sages and the monkeys and the \n",
            "sacrifice and said to him :- \n",
            "\" 0 King, thou hast come hither and as a \n",
            "destruction of the Gods, the son of Dasaratha, \n",
            "the monkeys and the sons of King Janaka and \n",
            "the death of the city of Lanka \n",
            "\n",
            "\n",
            "THEN the co\n",
            "\n",
            "truction of the \n",
            "worlds. The son of Dasaratha, \n",
            "the monkeys and the stars and \n",
            "the virtuous Rama, the mighty King of the Monkeys and the \n",
            "monkeys and the sages and the \n",
            "foremost of the Rakshasas and \n",
            "the country of Rama, the monkeys \n",
            "and the sages and the southern region \n",
            "and the son of King Dasarat\n",
            "\n",
            "####################\n",
            "Temperature: 0.5\n",
            "####################\n",
            "e prince with the \n",
            "wind surrounded by mercy to be done, 0 Thou of \n",
            "the Gods and the Rakshasas and \n",
            "\n",
            "\n",
            "1 At Lakshmana, he is dear to the \n",
            "monkeys with fresh the path of his foes, and the \n",
            "monkeys and the titans and the \n",
            "devas and the blood of the waters, and the instructions \n",
            "of the sacred fire, and t\n",
            "\n",
            "y sages and \n",
            "the solar of the foremost of the \n",
            "monkeys and seeing the divine \n",
            "Suras and titans and friendship with their \n",
            "friends, resembled a great serpent \n",
            "and the city of Lakshmana, they are no longer be able to destroy \n",
            "the peak of the other serpents and \n",
            "the titans and the princess and resplend\n",
            "\n",
            "\n",
            "foes, who was seated in the midst of the ascetic, \n",
            "the King of the Titans and the \n",
            "king and in the river Mandhata \n",
            "was the gods and the stars in \n",
            "blood, that magnanimous Rama and Lakshmana \n",
            "and the foremost of the monkeys. \n",
            "Thereafter, like unto a mountain, and the \n",
            "Lord of the Titans of the Gods a\n",
            "\n",
            "####################\n",
            "Temperature: 1.0\n",
            "####################\n",
            " of Panchana and that intrependent \n",
            "river horses. And or Rama pleased \n",
            "with free heroic strength and the owing of butter? \n",
            "cc And I am related the army, proceeded starting of his shafts who, affiesting the skies and \n",
            "troubled and where of subdue\n",
            "ruling their \n",
            "friends adorn their eldest serses ; \n",
            "res\n",
            "\n",
            "Ravana's adverches my servants \n",
            "\n",
            "\n",
            "THE offspring of the Chief of the \n",
            "Moon, the holy spherrit head and each other \n",
            "to righteousness, as also in the conversive \n",
            "mountain many city, rorted with \n",
            "master. \n",
            "Taking mine arms in extent and milk! First gem. 0 Sinful One, hear overcome injurisoes in the centr\n",
            "\n",
            "self upon him and, do \n",
            "thou weirs anxiety.\" After do so; \n",
            "that incomparable woman death have fearest as the same beings ascended to Indra that Vaimarishi 6 deem this arise, \n",
            "I see the foremost of Warriors. \n",
            "Her mantras fall and the owl and, whether in Janasthana's chief \n",
            "Raghava's matel1ity! coward \n",
            "\n",
            "Epoch 11/20\n",
            "2532/2532 [==============================] - 330s 130ms/step - loss: 1.0195\n",
            "Epoch 12/20\n",
            "2532/2532 [==============================] - 332s 131ms/step - loss: 1.0070\n",
            "Epoch 13/20\n",
            "2532/2532 [==============================] - 333s 132ms/step - loss: 0.9957\n",
            "Epoch 14/20\n",
            "2532/2532 [==============================] - 328s 130ms/step - loss: 0.9841\n",
            "Epoch 15/20\n",
            "2532/2532 [==============================] - 325s 128ms/step - loss: 0.9724\n",
            "####################\n",
            "Temperature: 0.2\n",
            "####################\n",
            "otection of the \n",
            "Gods and the titans and the country \n",
            "of the Gods and the Gods and the \n",
            "Gods and Asuras, who is the son of \n",
            "Dasaratha, who was able to change their form at will, who is \n",
            "subject to the sound of the sacrificial \n",
            "fire in the forest and the son of \n",
            "Dasaratha, the son of Dasaratha \n",
            "and t\n",
            "\n",
            " \n",
            "cc The destroyer of the world, the son of \n",
            "Dasaratha, the son of Dasaratha, he who \n",
            "had been sent to the capital and the \n",
            "sound of the princess and the \n",
            "princes and the son of Dasaratha, \n",
            "the son of Dasaratha, the son of Dasaratha and the \n",
            "waters of the monkeys and the \n",
            "chariot with the palace of \n",
            "\n",
            "n of Dasaratha and \n",
            "the Gods and the Gods and the \n",
            "Gods and the Gods and the Gods and the \n",
            "Gods and the Gods and the Gods and \n",
            "the Gods and the Gods and the \n",
            "Gods and the Gods and the Gods and Asuras, \n",
            "the Gods and the Gods and the \n",
            "Gods and the Gods and the Gods and the \n",
            "Gods and the Gods and the G\n",
            "\n",
            "####################\n",
            "Temperature: 0.5\n",
            "####################\n",
            "lace of Maruti was virtuous that he should return to the sacrifice. \n",
            "cc 0 Lakshmana, I shall suffer thy senses \n",
            "and my consort and the grass of his ministers \n",
            "and strength and respect and who is endowed with \n",
            "wealth, spreading them back and not have consulted himself on the battlefield and the \n",
            "son \n",
            "\n",
            "e king and the slave of that chariot, great and princess and said :- \n",
            "cc 0 Goddess, what is dear to thee \n",
            "and the forest with the great \n",
            "sages, with their traditions and \n",
            "sandalwood, who was as a second destruction of his \n",
            "son resembling the fire of the forest. \n",
            "The support of the city with his own \n",
            "\n",
            "\n",
            "preparations for a long time and \n",
            "protector the crags, and the shafts like unto a serpent or \n",
            "accomplishes that it is not the \n",
            "moon and the tumult and the son of \n",
            "Vayu is surrounded by streams of \n",
            "mountains, resembling a lotus stream \n",
            "of the traditional rites. It is the wicked \n",
            "Kaikeyi, who resembl\n",
            "\n",
            "####################\n",
            "Temperature: 1.0\n",
            "####################\n",
            "ither \n",
            "a sprayaur. Armed with an abundance of Rams, act and guiden belonging to the \n",
            "matter drove towards the law, he disport \n",
            "thee, 0 Devi, by fail, 0 Mighty Prahasta! I see no force \n",
            "to me. 0 Lord, have ever sent on what \n",
            "powerful confusion.\" \n",
            "By this commander of the Ashoka grow and slappings \n",
            "an\n",
            "\n",
            "ds, 0 Thou who wert obey the \n",
            "city.\" \n",
            "\n",
            "\n",
            "47 \n",
            "\n",
            "\n",
            "\n",
            "THE RAMAYANA OF VALMIKI \n",
            "she nor astonishing great prowess that is a vision of asvery \n",
            "warriors to Vasavai, King Dasaratha, full of effectable deeds and call and struck \n",
            "down the hide of Lanka, Sugriva transformed \n",
            "in slay, 0 Gentle Proy of thy \n",
            "name:- \n",
            "\n",
            "et fatigue in peace \n",
            "to Vishnu ! ' \n",
            "\" Like a thousand years. I am worthy of the sacrificial \n",
            "forest which was placed, was took \n",
            "pleasant earrings, and the hinger, seated \n",
            "by arrows to blue for this confidence \n",
            "to what thou konot I desire not in our \n",
            "sire, distressed our anguish Lakshmana passed to t\n",
            "\n",
            "Epoch 16/20\n",
            "2532/2532 [==============================] - 322s 127ms/step - loss: 0.9607\n",
            "Epoch 17/20\n",
            "2532/2532 [==============================] - 332s 131ms/step - loss: 0.9491\n",
            "Epoch 18/20\n",
            "2532/2532 [==============================] - 332s 131ms/step - loss: 0.9375\n",
            "Epoch 19/20\n",
            "2532/2532 [==============================] - 330s 130ms/step - loss: 0.9260\n",
            "Epoch 20/20\n",
            "2532/2532 [==============================] - 332s 131ms/step - loss: 0.9149\n",
            "####################\n",
            "Temperature: 0.2\n",
            "####################\n",
            "mand of the sages, \n",
            "the son of Dasaratha, the son of \n",
            "Dasaratha and the monkeys with the \n",
            "titans and the sages and the titans were struck down by the sages, \n",
            "the son of Dasaratha, having slain the titans and the \n",
            "sages and the monkeys and the \n",
            "country of Rama and Lakshmana and the \n",
            "son of Dasaratha \n",
            "\n",
            "country of Rama and Lakshmana and the \n",
            "monkeys should be seen in the forest and the \n",
            "sacrifice will be found in the \n",
            "forest, the son of Dasaratha and the \n",
            "sage with the sacrifice and the \n",
            "sacrifice in the forest, who were \n",
            "as the sun and moon and the stars of the sages, \n",
            "the monkeys resembled the su\n",
            "\n",
            " the Gods and \n",
            "Asuras and the titans with their \n",
            "courage, the son of the Wind-god and the titans, \n",
            "the destroyer of the worlds, the \n",
            "foremost of the Rakshasas, who was as the \n",
            "sun and moon and the sons of King Dasaratha and \n",
            "the descendant of Raghu, the son of Dasaratha and \n",
            "the monkeys and the sage\n",
            "\n",
            "####################\n",
            "Temperature: 0.5\n",
            "####################\n",
            "orld and the son of Anila, \n",
            "observing the two sons of the \n",
            "House of Raghu, the beautiful \n",
            "speech in the forest. \n",
            "Having committed the slaying of a thousand \n",
            "states and trees of every kind. \n",
            "He said: \"0 Lord, the king in an instant that the recollection of the Gods and Asuras and the \n",
            "whole earth is \n",
            "\n",
            "he king in the forest and the \n",
            "wise and the other monkeys without \n",
            "anxiety. If thou delight the king and the \n",
            "sandals of the sun and moon and servants and the \n",
            "waters of the sages, the valiant \n",
            "Shatanandi and my mother and the foremost of the monkeys and the \n",
            "sages was protects the city of Rama in t\n",
            "\n",
            "on a prey to play the company of the \n",
            "Sage Vishwamitra, the son of Maruta and the \n",
            "monkeys of the Sage Vishwamitra with its \n",
            "rituals, the monkeys trembled \n",
            "the death of death ! \" \n",
            "Then the mighty Hanuman, the son of heaven itself \n",
            "and the means of the rainy season, he replied :- \n",
            "cc 0 Blessed One, I\n",
            "\n",
            "####################\n",
            "Temperature: 1.0\n",
            "####################\n",
            "able to deep like a lion, made calamity bore the terror of his anger. Having accepted these words \n",
            "of Raghava, many deceiting flowering \n",
            "battle. On none hanging his instruction and great intellect with thy grief! It was formerly. Now \n",
            "Bharata and cross their lives four departure. The prowess of roya\n",
            "\n",
            "icate tones, Manu whose boon \n",
            "must take heart, this is help to the titans in seas for shouting, lay possessed of \n",
            "himself with con-litulat ever \n",
            "bestowed on him; therefore, provoked youth and in \n",
            "words with joined palms, said :- \n",
            "cc This matter none were mine own abode. None were mastered with their\n",
            "\n",
            "s, \n",
            "ascended a celestial partike, cut forth, whether he bears the scent \n",
            "of this toward and again, the aged titan among \n",
            "the sacrificial fires of my opposi- \n",
            "ity, would not listen, between the \n",
            "Goddess Poulastya and their leaders, in a \n",
            "brahmin of which I will destroy the kine \n",
            "and the third was fil\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rkFpMB6zRWlF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "outputId": "c6c873e8-5615-4361-be0c-df28f504b4b6"
      },
      "source": [
        "temperature = [1.0, 0.5, 0.2, 0.2]   \n",
        "prefix = None   # if you want each generated text to start with a given seed text\n",
        "\n",
        "if train_cfg['line_delimited']:\n",
        "  n = 1000\n",
        "  max_gen_length = 60 if model_cfg['word_level'] else 300\n",
        "else:\n",
        "  n = 1\n",
        "  max_gen_length = 2000 if model_cfg['word_level'] else 10000\n",
        "  \n",
        "timestring = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "gen_file = '{}_gentext_{}.txt'.format('ramayan RNN', timestring)\n",
        "\n",
        "textgen.generate_to_file(gen_file,\n",
        "                         temperature=temperature,\n",
        "                         prefix=prefix,\n",
        "                         n=n,\n",
        "                         max_gen_length=max_gen_length)\n",
        "files.download(gen_file)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-876b79c3412d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m                          \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m                          max_gen_length=max_gen_length)\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m    176\u001b[0m       \u001b[0;34m'port'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m       \u001b[0;34m'path'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m       \u001b[0;34m'name'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m   })\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result)\u001b[0m\n\u001b[1;32m     37\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    104\u001b[0m         reply.get('colab_msg_id') == message_id):\n\u001b[1;32m    105\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: TypeError: NetworkError when attempting to fetch resource."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R98j4_IuRhzp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "files.download('{}_weights.hdf5'.format(model_name))\n",
        "files.download('{}_vocab.json'.format(model_name))\n",
        "files.download('{}_config.json'.format(model_name))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}